{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/saad/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import nltk as nl\n",
    "import gensim\n",
    "nl.download('stopwords')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import classification_report\n",
    "from matplotlib.colors import ListedColormap as lcm\n",
    "import inspect, re\n",
    "porter_stemmer = PorterStemmer()\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    dataset = load_files(path)\n",
    "    return dataset['data'], dataset['target']\n",
    "\n",
    "def preprocess(docs):\n",
    "    #stop words removal\n",
    "    docs = [remove_stopwords(doc) for doc in docs]\n",
    "\n",
    "    #tokenization\n",
    "    docs = [gensim.utils.simple_preprocess(doc) for doc in docs] \n",
    "\n",
    "    #stemming\n",
    "    docs = [[porter_stemmer.stem(word) for word in doc] for doc in docs]\n",
    "\n",
    "    return docs\n",
    "\n",
    "\n",
    "def tfidf_vectorization(docs, decode):\n",
    "    # convert X from a list of tokens to a string, because \n",
    "    # fit_transform and transform functions below don't accept list of words\n",
    "    docs = [' '.join(doc) for doc in docs]    \n",
    "\n",
    "    tfidf_representer = TfidfVectorizer(stop_words = nl.corpus.stopwords.words('english'))\n",
    "\n",
    "    if decode:\n",
    "        docs = tfidf_representer.fit_transform(docs)\n",
    "    else:\n",
    "        docs = tfidf_representer.transform(docs)\n",
    "    return docs\n",
    "\n",
    "def build_evaluate_logistic_model(X_train, y_train, X_test, y_test, solver, dual, C, max_iter=1000):\n",
    "    model = LogisticRegression(solver = solver, dual = dual, C = C, tol=1e-3, max_iter=max_iter)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    print(\"Train Accuracy : \",accuracy_score(y_train,y_pred_train))\n",
    "    print(\"Test  Accuracy : \",accuracy_score(y_test,y_pred_test),'\\n')\n",
    "    return\n",
    "\n",
    "def build_evaluate_SVM_model(X_train, y_train, X_test, y_test, kernel):\n",
    "    model = svm.SVC(kernel=kernal)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    print(\"Train Accuracy : \",accuracy_score(y_train,y_pred_train))\n",
    "    print(\"Test  Accuracy : \",accuracy_score(y_test,y_pred_test),'\\n')\n",
    "    return   \n",
    "\n",
    "def build_evaluate_LinearSVM_model(X_train, y_train, X_test, y_test, tol , C, max_iter=10000):\n",
    "    model = svm.LinearSVC(tol = 1e-3, C = C, max_iter=max_iter)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    print(\"Train Accuracy : \",accuracy_score(y_train,y_pred_train))\n",
    "    print(\"Test  Accuracy : \",accuracy_score(y_test,y_pred_test),'\\n')\n",
    "    return \n",
    "\n",
    "def word2vec_vectorization(doc_words, model):\n",
    "    temp = np.empty(2000, dtype=object)\n",
    "    doc_vec = []\n",
    "    res = np.empty((2000,), dtype=object)\n",
    "    for j in range(len(doc_words)):\n",
    "        try:\n",
    "            word_vec = model.wv[doc_words[j]]\n",
    "            doc_vec.append(word_vec)\n",
    "        except KeyError:    # Ignore, if the word doesn't exist in the vocabulary\n",
    "            pass\n",
    "    res = np.mean(doc_vec, axis=0)  #return 1d vec of len 100\n",
    "    return res\n"
   ]
  },
  {
   "source": [
    "# Step 1\n",
    "# load the files and preprocessing them"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from files\n",
    "X, y = load_data(\"txt_sentoken\")\n",
    "\n",
    "#preprossing\n",
    "X = preprocess(X)\n",
    "\n",
    "#doc2vec model require the data to be TaggedDocument before training on it\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X)]"
   ]
  },
  {
   "source": [
    "# Step 2\n",
    "# Word Embedding models training\n",
    "- Train the doc2vec, word2vec skipgram, word2vec CBOW models\n",
    "- Note: You need to run this cell only once on your computer\n",
    "- It will take some time..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model = gensim.models.doc2vec.Doc2Vec(documents, vector_size=100, min_count=1, epochs=40, workers=multiprocessing.cpu_count(), window=3)\n",
    "doc2vec_model.save(\"doc2vec_100_1_40_3\")\n",
    "\n",
    "word2vec_skipgram_model = gensim.models.Word2Vec(sentences=X, size=100, window=3, sg=1, min_count=1, workers=multiprocessing.cpu_count(), iter=40)\n",
    "word2vec_skipgram_model.save(\"skipgram_100_3_1_40.model\")\n",
    "\n",
    "word2vec_CBOW_model = gensim.models.Word2Vec(sentences=X, size=100, window=3, sg=0, min_count=1, workers=multiprocessing.cpu_count(), iter=40)\n",
    "word2vec_CBOW_model.save(\"CBOW_100_3_1_40.model\")"
   ]
  },
  {
   "source": [
    "# Step 3\n",
    "# Load the trained Word Embedding Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the doc2vec skipgram model\n",
    "doc2vec_model = gensim.models.Doc2Vec.load(\"doc2vec_100_1_40_3\")\n",
    "\n",
    "#load the word2vec skipgram model\n",
    "word2vec_skipgram_model = gensim.models.Word2Vec.load(\"skipgram_100_3_1_40.model\")\n",
    "\n",
    "#load the word2vec CBOW model\n",
    "word2vec_CBOW_model = gensim.models.Word2Vec.load(\"CBOW_100_3_1_40.model\")"
   ]
  },
  {
   "source": [
    "# Step 4\n",
    "# Vectorization\n",
    "- It will take some time..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf vectorization\n",
    "X_tfidf = tfidf_vectorization(X, True)\n",
    "\n",
    "#doc2vec vectorization\n",
    "X_doc2vec = [doc2vec_model.infer_vector(doc) for doc in X]\n",
    "\n",
    "#word2vec skipgram vectorization\n",
    "X_word2vec_skipgram = [word2vec_vectorization(doc, word2vec_skipgram_model) for doc in X]\n",
    "\n",
    "#word2vec CBOW vectorization\n",
    "X_word2vec_CBOW = [word2vec_vectorization(doc, word2vec_CBOW_model) for doc in X]"
   ]
  },
  {
   "source": [
    "# Step 5\n",
    "# Train Test Split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf train test split\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y, test_size = 0.2, random_state = 0, stratify = y)\n",
    "unique, counts = np.unique(y_train_tfidf, return_counts=True)\n",
    "\n",
    "# doc2vec train test split\n",
    "X_train_doc2vec, X_test_doc2vec, y_train_doc2vec, y_test_doc2vec = train_test_split(X_doc2vec, y, test_size = 0.2, random_state = 0, stratify = y)\n",
    "unique, counts = np.unique(y_train_doc2vec, return_counts=True)\n",
    "\n",
    "# word2vec skipgram train test split\n",
    "X_train_word2vec_skipgram, X_test_word2vec_skipgram, y_train_word2vec_skipgram, y_test_word2vec_skipgram = train_test_split(X_word2vec_skipgram, y, test_size = 0.2, random_state = 0, stratify = y)\n",
    "unique, counts = np.unique(y_train_word2vec_skipgram, return_counts=True)\n",
    "\n",
    "# word2vec CBOW train test split\n",
    "X_train_word2vec_CBOW, X_test_word2vec_CBOW, y_train_word2vec_CBOW, y_test_word2vec_CBOW = train_test_split(X_word2vec_CBOW, y, test_size = 0.2, random_state = 0, stratify = y)\n",
    "unique, counts = np.unique(y_train_word2vec_CBOW, return_counts=True)"
   ]
  },
  {
   "source": [
    "# Step 6\n",
    "# Vectors Normalization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "#no normalization for tfidf vectors, because tfidf vectorization function do the normalization for us\n",
    "\n",
    "#doc2vec vector normalization\n",
    "scaler.fit(X_train_doc2vec)\n",
    "X_train_doc2vec = scaler.transform(X_train_doc2vec)\n",
    "X_test_doc2vec = scaler.transform(X_test_doc2vec)\n",
    "\n",
    "#word2vec skipgram vector normalization\n",
    "scaler.fit(X_train_word2vec_skipgram)\n",
    "X_train_word2vec_skipgram = scaler.transform(X_train_word2vec_skipgram)\n",
    "X_test_word2vec_skipgram = scaler.transform(X_test_word2vec_skipgram)\n",
    "\n",
    "#word2vec CBOW vector normalization\n",
    "scaler.fit(X_train_word2vec_CBOW)\n",
    "X_train_word2vec_CBOW = scaler.transform(X_train_word2vec_CBOW)\n",
    "X_test_word2vec_CBOW = scaler.transform(X_test_word2vec_CBOW)"
   ]
  },
  {
   "source": [
    "# Step 7\n",
    "# Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------------ TF-IDF vectors Classification ------------------------\n",
      "\n",
      "\n",
      "---------------------- Logistic Regression ------------------------------\n",
      "\n",
      "--------------------------- liblinear --------------------------------\n",
      "\n",
      "Train Accuracy :  0.97625\n",
      "Test  Accuracy :  0.795 \n",
      "\n",
      "Train Accuracy :  0.9725\n",
      "Test  Accuracy :  0.7975 \n",
      "\n",
      "Train Accuracy :  0.958125\n",
      "Test  Accuracy :  0.785 \n",
      "\n",
      "Train Accuracy :  0.91\n",
      "Test  Accuracy :  0.7575 \n",
      "\n",
      "Train Accuracy :  0.933125\n",
      "Test  Accuracy :  0.7875 \n",
      "\n",
      "\n",
      "--------------------------- lbfgs --------------------------------\n",
      "\n",
      "Train Accuracy :  0.97625\n",
      "Test  Accuracy :  0.795 \n",
      "\n",
      "Train Accuracy :  0.9725\n",
      "Test  Accuracy :  0.7975 \n",
      "\n",
      "Train Accuracy :  0.958125\n",
      "Test  Accuracy :  0.785 \n",
      "\n",
      "Train Accuracy :  0.5\n",
      "Test  Accuracy :  0.5 \n",
      "\n",
      "Train Accuracy :  0.933125\n",
      "Test  Accuracy :  0.7875 \n",
      "\n",
      "\n",
      "--------------------------- saga --------------------------------\n",
      "\n",
      "Train Accuracy :  0.97625\n",
      "Test  Accuracy :  0.7975 \n",
      "\n",
      "Train Accuracy :  0.973125\n",
      "Test  Accuracy :  0.7975 \n",
      "\n",
      "Train Accuracy :  0.95875\n",
      "Test  Accuracy :  0.785 \n",
      "\n",
      "Train Accuracy :  0.50125\n",
      "Test  Accuracy :  0.5 \n",
      "\n",
      "Train Accuracy :  0.933125\n",
      "Test  Accuracy :  0.785 \n",
      "\n",
      "\n",
      "--------------------------- newton-cg --------------------------------\n",
      "\n",
      "Train Accuracy :  0.97625\n",
      "Test  Accuracy :  0.795 \n",
      "\n",
      "Train Accuracy :  0.9725\n",
      "Test  Accuracy :  0.7975 \n",
      "\n",
      "Train Accuracy :  0.958125\n",
      "Test  Accuracy :  0.785 \n",
      "\n",
      "Train Accuracy :  0.91\n",
      "Test  Accuracy :  0.76 \n",
      "\n",
      "Train Accuracy :  0.933125\n",
      "Test  Accuracy :  0.7875 \n",
      "\n",
      "\n",
      "----------------------- Linear SVM --------------------------------\n",
      "Train Accuracy :  1.0\n",
      "Test  Accuracy :  0.8025 \n",
      "\n",
      "Train Accuracy :  1.0\n",
      "Test  Accuracy :  0.8025 \n",
      "\n",
      "Train Accuracy :  0.996875\n",
      "Test  Accuracy :  0.8075 \n",
      "\n",
      "Train Accuracy :  0.91\n",
      "Test  Accuracy :  0.76 \n",
      "\n",
      "Train Accuracy :  0.98625\n",
      "Test  Accuracy :  0.8075 \n",
      "\n",
      "Train Accuracy :  1.0\n",
      "Test  Accuracy :  0.8025 \n",
      "\n",
      "Train Accuracy :  0.971875\n",
      "Test  Accuracy :  0.7925 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\n------------------ TF-IDF vectors Classification ------------------------\\n')\n",
    "\n",
    "\n",
    "print('\\n---------------------- Logistic Regression ------------------------------')\n",
    "\n",
    "print('\\n--------------------------- liblinear --------------------------------\\n')\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'liblinear', True, 1)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'liblinear', True, 0.9)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'liblinear', True, 0.5)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'liblinear', True, 0.000000000000000001)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'liblinear', True, 0.2)\n",
    "\n",
    "\n",
    "print('\\n--------------------------- lbfgs --------------------------------\\n')\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'lbfgs', False, 1)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'lbfgs', False, 0.9)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'lbfgs', False, 0.5)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'lbfgs', False, 0.000000000000000001)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'lbfgs', False, 0.2)\n",
    "\n",
    "\n",
    "print('\\n--------------------------- saga --------------------------------\\n')\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'saga', False, 1)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'saga', False, 0.9)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'saga', False, 0.5)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'saga', False, 0.000000000000000001)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'saga', False, 0.2)\n",
    "\n",
    "\n",
    "print('\\n--------------------------- newton-cg --------------------------------\\n')\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'newton-cg', False, 1)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'newton-cg', False, 0.9)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'newton-cg', False, 0.5)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'newton-cg', False, 0.000000000000000001)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, 'newton-cg', False, 0.2)\n",
    "\n",
    "\n",
    "print('\\n----------------------- Linear SVM --------------------------------')\n",
    "build_evaluate_LinearSVM_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, tol = 1e-5, C = 1)\n",
    "build_evaluate_LinearSVM_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, tol = 1e-5, C = 0.9)\n",
    "build_evaluate_LinearSVM_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, tol = 1e-5, C = 0.5)\n",
    "build_evaluate_LinearSVM_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, tol = 1e-5, C = 0.000000000000000001)\n",
    "build_evaluate_LinearSVM_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, tol = 1e-5, C = 0.2)\n",
    "build_evaluate_LinearSVM_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, tol = 1e-3, C = 1)\n",
    "build_evaluate_LinearSVM_model(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf, tol = 1e-1, C = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------------ doc2vec vectors Classification ------------------------\n",
      "\n",
      "\n",
      "---------------------- Logistic Regression ------------------------------\n",
      "\n",
      "--------------------------- liblinear --------------------------------\n",
      "\n",
      "Train Accuracy :  0.87\n",
      "Test  Accuracy :  0.795 \n",
      "\n",
      "Train Accuracy :  0.87\n",
      "Test  Accuracy :  0.795 \n",
      "\n",
      "Train Accuracy :  0.869375\n",
      "Test  Accuracy :  0.795 \n",
      "\n",
      "Train Accuracy :  0.798125\n",
      "Test  Accuracy :  0.7525 \n",
      "\n",
      "Train Accuracy :  0.871875\n",
      "Test  Accuracy :  0.7925 \n",
      "\n",
      "\n",
      "--------------------------- lbfgs --------------------------------\n",
      "\n",
      "Train Accuracy :  0.870625\n",
      "Test  Accuracy :  0.795 \n",
      "\n",
      "Train Accuracy :  0.87\n",
      "Test  Accuracy :  0.795 \n",
      "\n",
      "Train Accuracy :  0.869375\n",
      "Test  Accuracy :  0.795 \n",
      "\n",
      "Train Accuracy :  0.798125\n",
      "Test  Accuracy :  0.7525 \n",
      "\n",
      "Train Accuracy :  0.871875\n",
      "Test  Accuracy :  0.7925 \n",
      "\n",
      "\n",
      "--------------------------- saga --------------------------------\n",
      "\n",
      "Train Accuracy :  0.870625\n",
      "Test  Accuracy :  0.795 \n",
      "\n",
      "Train Accuracy :  0.87\n",
      "Test  Accuracy :  0.795 \n",
      "\n",
      "Train Accuracy :  0.869375\n",
      "Test  Accuracy :  0.795 \n",
      "\n",
      "Train Accuracy :  0.5\n",
      "Test  Accuracy :  0.5 \n",
      "\n",
      "Train Accuracy :  0.871875\n",
      "Test  Accuracy :  0.795 \n",
      "\n",
      "\n",
      "--------------------------- newton-cg --------------------------------\n",
      "\n",
      "Train Accuracy :  0.870625\n",
      "Test  Accuracy :  0.795 \n",
      "\n",
      "Train Accuracy :  0.87\n",
      "Test  Accuracy :  0.795 \n",
      "\n",
      "Train Accuracy :  0.869375\n",
      "Test  Accuracy :  0.795 \n",
      "\n",
      "Train Accuracy :  0.798125\n",
      "Test  Accuracy :  0.7525 \n",
      "\n",
      "Train Accuracy :  0.871875\n",
      "Test  Accuracy :  0.7925 \n",
      "\n",
      "\n",
      "----------------------- Linear SVM --------------------------------\n",
      "Train Accuracy :  0.87125\n",
      "Test  Accuracy :  0.79 \n",
      "\n",
      "Train Accuracy :  0.87125\n",
      "Test  Accuracy :  0.79 \n",
      "\n",
      "Train Accuracy :  0.87125\n",
      "Test  Accuracy :  0.79 \n",
      "\n",
      "Train Accuracy :  0.798125\n",
      "Test  Accuracy :  0.7525 \n",
      "\n",
      "Train Accuracy :  0.87125\n",
      "Test  Accuracy :  0.79 \n",
      "\n",
      "Train Accuracy :  0.87125\n",
      "Test  Accuracy :  0.79 \n",
      "\n",
      "Train Accuracy :  0.87125\n",
      "Test  Accuracy :  0.79 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\n------------------ doc2vec vectors Classification ------------------------\\n')\n",
    "\n",
    "\n",
    "print('\\n---------------------- Logistic Regression ------------------------------')\n",
    "\n",
    "print('\\n--------------------------- liblinear --------------------------------\\n')\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'liblinear', True, 1)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'liblinear', True, 0.9)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'liblinear', True, 0.5)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'liblinear', True, 0.000000000000000001)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'liblinear', True, 0.2)\n",
    "\n",
    "\n",
    "print('\\n--------------------------- lbfgs --------------------------------\\n')\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'lbfgs', False, 1)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'lbfgs', False, 0.9)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'lbfgs', False, 0.5)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'lbfgs', False, 0.000000000000000001)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'lbfgs', False, 0.2)\n",
    "\n",
    "\n",
    "print('\\n--------------------------- saga --------------------------------\\n')\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'saga', False, 1)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'saga', False, 0.9)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'saga', False, 0.5)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'saga', False, 0.000000000000000001)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'saga', False, 0.2)\n",
    "\n",
    "\n",
    "print('\\n--------------------------- newton-cg --------------------------------\\n')\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'newton-cg', False, 1)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'newton-cg', False, 0.9)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'newton-cg', False, 0.5)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'newton-cg', False, 0.000000000000000001)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, 'newton-cg', False, 0.2)\n",
    "\n",
    "\n",
    "print('\\n----------------------- Linear SVM --------------------------------')\n",
    "build_evaluate_LinearSVM_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, tol = 1e-5, C = 1)\n",
    "build_evaluate_LinearSVM_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, tol = 1e-5, C = 0.9)\n",
    "build_evaluate_LinearSVM_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, tol = 1e-5, C = 0.5)\n",
    "build_evaluate_LinearSVM_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, tol = 1e-5, C = 0.000000000000000001)\n",
    "build_evaluate_LinearSVM_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, tol = 1e-5, C = 0.2)\n",
    "build_evaluate_LinearSVM_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, tol = 1e-3, C = 1)\n",
    "build_evaluate_LinearSVM_model(X_train_doc2vec, y_train_doc2vec, X_test_doc2vec, y_test_doc2vec, tol = 1e-1, C = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------------ word2vec skipgram vectors Classification ------------------------\n",
      "\n",
      "\n",
      "------------------------- Logistic Regression ------------------------------\n",
      "\n",
      "----------------------------- liblinear --------------------------------\n",
      "\n",
      "Train Accuracy :  0.841875\n",
      "Test  Accuracy :  0.76 \n",
      "\n",
      "Train Accuracy :  0.841875\n",
      "Test  Accuracy :  0.76 \n",
      "\n",
      "Train Accuracy :  0.8425\n",
      "Test  Accuracy :  0.7625 \n",
      "\n",
      "Train Accuracy :  0.760625\n",
      "Test  Accuracy :  0.6975 \n",
      "\n",
      "Train Accuracy :  0.844375\n",
      "Test  Accuracy :  0.7725 \n",
      "\n",
      "\n",
      "--------------------------- lbfgs --------------------------------\n",
      "\n",
      "Train Accuracy :  0.841875\n",
      "Test  Accuracy :  0.76 \n",
      "\n",
      "Train Accuracy :  0.841875\n",
      "Test  Accuracy :  0.76 \n",
      "\n",
      "Train Accuracy :  0.8425\n",
      "Test  Accuracy :  0.7625 \n",
      "\n",
      "Train Accuracy :  0.760625\n",
      "Test  Accuracy :  0.6975 \n",
      "\n",
      "Train Accuracy :  0.844375\n",
      "Test  Accuracy :  0.7725 \n",
      "\n",
      "\n",
      "--------------------------- saga --------------------------------\n",
      "\n",
      "Train Accuracy :  0.841875\n",
      "Test  Accuracy :  0.76 \n",
      "\n",
      "Train Accuracy :  0.841875\n",
      "Test  Accuracy :  0.76 \n",
      "\n",
      "Train Accuracy :  0.84125\n",
      "Test  Accuracy :  0.7625 \n",
      "\n",
      "Train Accuracy :  0.57125\n",
      "Test  Accuracy :  0.56 \n",
      "\n",
      "Train Accuracy :  0.84375\n",
      "Test  Accuracy :  0.7725 \n",
      "\n",
      "\n",
      "--------------------------- newton-cg --------------------------------\n",
      "\n",
      "Train Accuracy :  0.841875\n",
      "Test  Accuracy :  0.76 \n",
      "\n",
      "Train Accuracy :  0.841875\n",
      "Test  Accuracy :  0.76 \n",
      "\n",
      "Train Accuracy :  0.8425\n",
      "Test  Accuracy :  0.7625 \n",
      "\n",
      "Train Accuracy :  0.760625\n",
      "Test  Accuracy :  0.6975 \n",
      "\n",
      "Train Accuracy :  0.844375\n",
      "Test  Accuracy :  0.7725 \n",
      "\n",
      "\n",
      "----------------------- Linear SVM --------------------------------\n",
      "Train Accuracy :  0.840625\n",
      "Test  Accuracy :  0.7625 \n",
      "\n",
      "Train Accuracy :  0.840625\n",
      "Test  Accuracy :  0.7625 \n",
      "\n",
      "Train Accuracy :  0.840625\n",
      "Test  Accuracy :  0.7625 \n",
      "\n",
      "Train Accuracy :  0.760625\n",
      "Test  Accuracy :  0.6975 \n",
      "\n",
      "Train Accuracy :  0.840625\n",
      "Test  Accuracy :  0.7625 \n",
      "\n",
      "Train Accuracy :  0.840625\n",
      "Test  Accuracy :  0.7625 \n",
      "\n",
      "Train Accuracy :  0.84\n",
      "Test  Accuracy :  0.765 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\n------------------ word2vec skipgram vectors Classification ------------------------\\n')\n",
    "\n",
    "\n",
    "print('\\n------------------------- Logistic Regression ------------------------------')\n",
    "\n",
    "print('\\n----------------------------- liblinear --------------------------------\\n')\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'liblinear', True, 1)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'liblinear', True, 0.9)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'liblinear', True, 0.5)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'liblinear', True, 0.000000000000000001)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'liblinear', True, 0.2)\n",
    "\n",
    "\n",
    "print('\\n--------------------------- lbfgs --------------------------------\\n')\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'lbfgs', False, 1)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'lbfgs', False, 0.9)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'lbfgs', False, 0.5)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'lbfgs', False, 0.000000000000000001)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'lbfgs', False, 0.2)\n",
    "\n",
    "\n",
    "print('\\n--------------------------- saga --------------------------------\\n')\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'saga', False, 1)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'saga', False, 0.9)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'saga', False, 0.5)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'saga', False, 0.000000000000000001)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'saga', False, 0.2)\n",
    "\n",
    "\n",
    "print('\\n--------------------------- newton-cg --------------------------------\\n')\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'newton-cg', False, 1)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'newton-cg', False, 0.9)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'newton-cg', False, 0.5)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'newton-cg', False, 0.000000000000000001)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, 'newton-cg', False, 0.2)\n",
    "\n",
    "\n",
    "print('\\n----------------------- Linear SVM --------------------------------')\n",
    "build_evaluate_LinearSVM_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, tol = 1e-5, C = 1)\n",
    "build_evaluate_LinearSVM_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, tol = 1e-5, C = 0.9)\n",
    "build_evaluate_LinearSVM_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, tol = 1e-5, C = 0.5)\n",
    "build_evaluate_LinearSVM_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, tol = 1e-5, C = 0.000000000000000001)\n",
    "build_evaluate_LinearSVM_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, tol = 1e-5, C = 0.2)\n",
    "build_evaluate_LinearSVM_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, tol = 1e-3, C = 1)\n",
    "build_evaluate_LinearSVM_model(X_train_word2vec_skipgram, y_train_word2vec_skipgram, X_test_word2vec_skipgram, y_test_word2vec_skipgram, tol = 1e-1, C = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "------------------ word2vec CBOW vectors Classification ------------------------\n",
      "\n",
      "\n",
      "---------------------- Logistic Regression ------------------------------\n",
      "\n",
      "--------------------------- liblinear --------------------------------\n",
      "\n",
      "Train Accuracy :  0.835\n",
      "Test  Accuracy :  0.7775 \n",
      "\n",
      "Train Accuracy :  0.834375\n",
      "Test  Accuracy :  0.7775 \n",
      "\n",
      "Train Accuracy :  0.835625\n",
      "Test  Accuracy :  0.7775 \n",
      "\n",
      "Train Accuracy :  0.724375\n",
      "Test  Accuracy :  0.67 \n",
      "\n",
      "Train Accuracy :  0.8325\n",
      "Test  Accuracy :  0.78 \n",
      "\n",
      "\n",
      "--------------------------- lbfgs --------------------------------\n",
      "\n",
      "Train Accuracy :  0.835\n",
      "Test  Accuracy :  0.7775 \n",
      "\n",
      "Train Accuracy :  0.834375\n",
      "Test  Accuracy :  0.7775 \n",
      "\n",
      "Train Accuracy :  0.835625\n",
      "Test  Accuracy :  0.7775 \n",
      "\n",
      "Train Accuracy :  0.724375\n",
      "Test  Accuracy :  0.67 \n",
      "\n",
      "Train Accuracy :  0.8325\n",
      "Test  Accuracy :  0.78 \n",
      "\n",
      "\n",
      "--------------------------- saga --------------------------------\n",
      "\n",
      "Train Accuracy :  0.834375\n",
      "Test  Accuracy :  0.7775 \n",
      "\n",
      "Train Accuracy :  0.834375\n",
      "Test  Accuracy :  0.7775 \n",
      "\n",
      "Train Accuracy :  0.833125\n",
      "Test  Accuracy :  0.78 \n",
      "\n",
      "Train Accuracy :  0.6075\n",
      "Test  Accuracy :  0.5925 \n",
      "\n",
      "Train Accuracy :  0.83125\n",
      "Test  Accuracy :  0.7825 \n",
      "\n",
      "\n",
      "--------------------------- newton-cg --------------------------------\n",
      "\n",
      "Train Accuracy :  0.835\n",
      "Test  Accuracy :  0.7775 \n",
      "\n",
      "Train Accuracy :  0.834375\n",
      "Test  Accuracy :  0.7775 \n",
      "\n",
      "Train Accuracy :  0.835625\n",
      "Test  Accuracy :  0.7775 \n",
      "\n",
      "Train Accuracy :  0.724375\n",
      "Test  Accuracy :  0.67 \n",
      "\n",
      "Train Accuracy :  0.8325\n",
      "Test  Accuracy :  0.78 \n",
      "\n",
      "\n",
      "-------------------------- Linear SVM --------------------------------\n",
      "Train Accuracy :  0.834375\n",
      "Test  Accuracy :  0.7775 \n",
      "\n",
      "Train Accuracy :  0.834375\n",
      "Test  Accuracy :  0.7775 \n",
      "\n",
      "Train Accuracy :  0.834375\n",
      "Test  Accuracy :  0.7775 \n",
      "\n",
      "Train Accuracy :  0.724375\n",
      "Test  Accuracy :  0.67 \n",
      "\n",
      "Train Accuracy :  0.834375\n",
      "Test  Accuracy :  0.7775 \n",
      "\n",
      "Train Accuracy :  0.834375\n",
      "Test  Accuracy :  0.7775 \n",
      "\n",
      "Train Accuracy :  0.834375\n",
      "Test  Accuracy :  0.7775 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('\\n------------------ word2vec CBOW vectors Classification ------------------------\\n')\n",
    "\n",
    "\n",
    "print('\\n---------------------- Logistic Regression ------------------------------')\n",
    "\n",
    "print('\\n--------------------------- liblinear --------------------------------\\n')\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'liblinear', True, 1)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'liblinear', True, 0.9)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'liblinear', True, 0.5)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'liblinear', True, 0.000000000000000001)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'liblinear', True, 0.2)\n",
    "\n",
    "\n",
    "print('\\n--------------------------- lbfgs --------------------------------\\n')\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'lbfgs', False, 1)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'lbfgs', False, 0.9)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'lbfgs', False, 0.5)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'lbfgs', False, 0.000000000000000001)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'lbfgs', False, 0.2)\n",
    "\n",
    "\n",
    "print('\\n--------------------------- saga --------------------------------\\n')\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'saga', False, 1)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'saga', False, 0.9)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'saga', False, 0.5)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'saga', False, 0.000000000000000001)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'saga', False, 0.2)\n",
    "\n",
    "\n",
    "print('\\n--------------------------- newton-cg --------------------------------\\n')\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'newton-cg', False, 1)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'newton-cg', False, 0.9)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'newton-cg', False, 0.5)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'newton-cg', False, 0.000000000000000001)\n",
    "\n",
    "build_evaluate_logistic_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, 'newton-cg', False, 0.2)\n",
    "\n",
    "\n",
    "print('\\n-------------------------- Linear SVM --------------------------------')\n",
    "build_evaluate_LinearSVM_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, tol = 1e-5, C = 1)\n",
    "build_evaluate_LinearSVM_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, tol = 1e-5, C = 0.9)\n",
    "build_evaluate_LinearSVM_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, tol = 1e-5, C = 0.5)\n",
    "build_evaluate_LinearSVM_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, tol = 1e-5, C = 0.000000000000000001)\n",
    "build_evaluate_LinearSVM_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, tol = 1e-5, C = 0.2)\n",
    "build_evaluate_LinearSVM_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, tol = 1e-3, C = 1)\n",
    "build_evaluate_LinearSVM_model(X_train_word2vec_CBOW, y_train_word2vec_CBOW, X_test_word2vec_CBOW, y_test_word2vec_CBOW, tol = 1e-1, C = 0.1)\n"
   ]
  },
  {
   "source": [
    "# APPENDIX"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Accuracy :  0.99375\nTest  Accuracy :  0.815 \n\n"
     ]
    }
   ],
   "source": [
    "svm_model1 = svm.SVC(kernel='linear')\n",
    "\n",
    "build_evaluate_SVM_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
    "#https://github.com/scikit-learn/scikit-learn/issues/11536\n",
    "\n",
    "#https://medium.com/swlh/sentiment-classification-for-reviews-using-doc2vec-660ba594c336#_=_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0b11f76013f1207593403df959f42b4fea27784982535ba812f36c8e41478dc5b",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}